#Author				:	Papaioannou Vassilis
#Last update		:	09/ 01/ 2016
#Previous update	:	none
#Platform			:	ASAP IReS
#Github				:	https://github.com/project-asap/IReS-Platform
#Work package		:	Telecom analytics
#Github				:	https://github.com/project-asap/telecom-analytics/blob/current/docs/PeakDetection.md
################################################################################
#
#Description
#	This is the concrete version of the data_filter operator from wind workflow.
#Description_End

#################
# CONFIGURATION #
#################
#OPERATOR
Constraints.OpSpecification.Algorithm.name=data_filter
#ENGINE
Constraints.EngineSpecification.Distributed=Spark
#INPUT( mandatory)
Constraints.Input.number=1
Constraints.Input0.Engine.FS=HDFS
#if the input type is specified it should be also specified appropriately into
#the corresponding dataset description file
#Constraints.Input0.type=TextFile
#OUTPUT( mandatory)
Constraints.Output.number=1
Constraints.Output0.Engine.FS=HDFS

############
# MODELING #
############
#OPTIMIZATION METRIC( mandatory inputSpace, outputSpace properties)
Optimization.inputSpace.In0.size=Double,1E8,1E10,l
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.outputSpace.execTime=Double
Optimization.execTime=2.0

#############
# EXECUTION #
#############
#LUA CONFIGURATION FILE( mandatory)
Execution.LuaScript=Data_Filter.lua
#EXECUTION ARGUMENTS( optional)
Execution.Arguments.number=8
Execution.Argument0=spark://localhost:7077
Execution.Argument1=/dataset_simulated
Execution.Argument2=/output
Execution.Argument3=2015-06-01
Execution.Argument4=2015-06-02
Execution.Argument5=2015-06-03
Execution.Argument6=None
Execution.Argument7=/voronoi
#EXECUTION OUTPUT( mandatory)
Execution.Output0.path=$HDFS_OP_DIR/data_filter.txt
