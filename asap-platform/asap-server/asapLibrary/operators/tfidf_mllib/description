#Thu Jun 16 16:52:18 EEST 2016
Constraints.Input.number=1
Constraints.Engine=Spark
Constraints.OpSpecification.Algorithm.name=TF_IDF
Constraints.Output.number=1
Constraints.Input0.Engine.FS=HDFS
Constraints.Output0.Engine.FS=HDFS
Constraints.Output0.type=tfidf
Execution.Output0.inType=spark
Execution.Output0.path=$HDFS_OP_DIR/tfidf
Execution.Arguments.number=4
Execution.Argument0=In0.path
Execution.Argument1=$HDFS_OP_DIR/tfidf
Execution.Argument2=Optimization.totalCores
Execution.Argument3=Optimization.memory
Execution.memory=1024
Execution.cores=1
Optimization.memory=1024
Optimization.cores=1
Optimization.inputSpace.In0.documents=Double,10000.0,150000.0,10000.0
Optimization.inputSpace.memory=Double, 1024.0, 6000.0, 1024.0
Optimization.inputSpace.totalCores=Integer, 2, 36, 2
Optimization.inputSource.type=mongodb
Optimization.inputSource.host=master
Optimization.inputSource.db=metrics
Optimization.model.cost=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.execTime=Double
Optimization.outputSpace.Out0.documents=Integer
Optimization.cost=10
Optimization.outputSpace.cost=Double
Optimization.model.Out0.documents=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.Out0.documents=In0.documents
