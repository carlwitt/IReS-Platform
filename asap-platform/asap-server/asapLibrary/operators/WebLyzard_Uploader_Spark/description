#Author				:	Sofia Papagiannaki
#Last update		:	07/ 04/ 2016
#Previous update	:	
#Platform			:	ASAP IReS
#Github				:	https://github.com/project-asap/IReS-Platform
#Work package		:	Telecom analytics
#Github				:	
################################################################################
#
#Description
#	This is the concrete version of the WebLyzard Uploader operator from 
#	wind workflow.
#Description_End

#################
# CONFIGURATION #
#################
#OPERATOR
Constraints.OpSpecification.Algorithm.name=WebLyzard_Uploader
#ENGINE
Constraints.Engine=Spark
Constraints.EngineSpecification.Distributed=Spark
#INPUT( mandatory)
Constraints.Input.number=1
Constraints.Input0.Engine.FS=HDFS
#if the input type is specified it should be also specified appropriately into
#the corresponding dataset description file
#Constraints.Input0.type=TextFile
#OUTPUT( mandatory)
Constraints.Output.number=1
Constraints.Output0.Engine.FS=HDFS

############
# MODELING #
############
#OPTIMIZATION DIMENSIONS( mandatory, at least one)
#type,min_value,max_value,step
Optimization.inputSpace.region=Double,1.0,10.0,1.0
Optimization.inputSpace.timeFrame=Double,62015.0,122015.0,30000.0
#OPTIMIZATION METRIC( mandatory)
Optimization.outputSpace.execTime=Double
#optimization metric function
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.model.cost=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.cost=1.0

#############
# EXECUTION #
#############
#LUA CONFIGURATION FILE( mandatory)
Execution.LuaScript=WebLyzard_Uploader_Spark.lua
#EXECUTION ARGUMENTS( optional)
Execution.Arguments.number=4
Execution.Argument0=spark://131.114.136.218:7077
Execution.Argument1=upload.py
Execution.Argument2=wl_timeseries-roma-june-july-2015-aree_roma-area_presence.json
Execution.Argument3=the_password
#EXECUTION COPY FILES( optional)
#copy input to operator's local folder to use it
Execution.copyToLocal=In0.path
#copy operator's output to HDFS so as the following operator to access it
Execution.copyFromLocal=response_status
#EXECUTION OUTPUT( mandatory)
Execution.Output0.path=$HDFS_OP_DIR/response_status
