#
#Mon Jul 25 18:10:38 EEST 2016
Execution.copyFromLocal=vectorized.txt,normalized.csv
Execution.Argument2=vectorized.txt
Optimization.model.execTime=gr.ntua.ece.cslab.panic.core.models.UserFunction
Constraints.Input1.type=w2v_model
Execution.Argument1=In1.path.local
Execution.Argument0=In0.path.local
Execution.LuaScript=w2v_vectorize_python.lua
Execution.copyToLocal=In0.path,In1.path
Constraints.Input0.Engine.FS=HDFS
Constraints.Output0.Engine.FS=HDFS
Optimization.model.cost=gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.inputSpace.In0.documents=Double,10000.0,160000.0,10000.0
Constraints.Output0.type=vectors
Constraints.Input1.Engine.FS=HDFS
Constraints.OpSpecification.Algorithm.name=w2v_vectorize
Constraints.Output.number=1
Constraints.Engine=Python
Execution.Output0.path=$HDFS_OP_DIR/vectorized.txt
Optimization.outputSpace.execTime=Double
Optimization.outputSpace.Out0.points=Double
Execution.Arguments.number=3
Optimization.execTime=In0.documents*(0.063/log(1024))
Optimization.Out0.points=In0.documents
Constraints.Input.number=2
Optimization.cost=log(1024)
Optimization.outputSpace.cost=Double
Constraints.Input0.type=csv
Optimization.model.Out0.points=gr.ntua.ece.cslab.panic.core.models.UserFunction
