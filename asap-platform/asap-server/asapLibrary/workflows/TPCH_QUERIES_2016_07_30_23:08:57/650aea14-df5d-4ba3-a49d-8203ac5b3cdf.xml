<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<workflow>
    <operators>
        <name>lineitem</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = PostgreSQL
Constraints.Engine.location = slave-1
Constraints.type = SQL
Execution.name = lineitem
Execution.schema = ( l_orderkey bigint, l_partkey bigint, l_suppkey bigint, l_linenumber int, l_quantity decimal, l_extendedprice decimal, l_discount decimal, l_tax decimal, l_returnflag char( 1),   l_linestatus char( 1), l_shipdate date, l_commitdate date, l_receiptdate date, l_shipinstruct char( 25), l_shipmode char( 10), l_comment varchar( 44))
Optimization.size = 1
</description>
        <abstractName>lineitem</abstractName>
        <isTarget>false</isTarget>
    </operators>
    <operators>
        <name>Move_Postgres_Hive_3</name>
        <cost>10.24</cost>
        <execTime>10.24</execTime>
        <status>stopped</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = HIVE
Constraints.EngineSpecification.Distributed.HIVE.masterLocation = slave-1
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = PostgreSQL
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = move
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = HIVE
Constraints.Output0.Engine.location = slave-1
Constraints.Output0.type = SQL
Execution.Argument0 = postgres
Execution.Argument1 = In0.name
Execution.Argument2 = In0.schema
Execution.Arguments.number = 3
Execution.LuaScript = Move_Postgres_Hive.lua
Execution.Output0.name = In0.name
Execution.Output0.schema = In0.schema
Optimization.Out0.size = In0.size
Optimization.cost = 1.0
Optimization.execTime = In0.size/1.2
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>lineitem</input>
    </operators>
    <operators>
        <name>t0</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>stopped</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = HIVE
Constraints.Engine.location = slave-1
Constraints.type = SQL
Execution.name = lineitem
Execution.schema = ( l_orderkey bigint, l_partkey bigint, l_suppkey bigint, l_linenumber int, l_quantity decimal, l_extendedprice decimal, l_discount decimal, l_tax decimal, l_returnflag char( 1),   l_linestatus char( 1), l_shipdate date, l_commitdate date, l_receiptdate date, l_shipinstruct char( 25), l_shipmode char( 10), l_comment varchar( 44))
Optimization.size = 1.0
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>Move_Postgres_Hive_3</input>
    </operators>
    <operators>
        <name>InnerSQL_Hive_0</name>
        <cost>50000.00</cost>
        <execTime>50000.00</execTime>
        <status>stopped</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = HIVE
Constraints.EngineSpecification.Distributed.HIVE.masterLocation = master
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = HIVE
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = SQL_query
Constraints.OpSpecification.SQL_query = &quot;SELECT l_partkey AS agg_partkey, 0.2 * avg(l_quantity) AS avg_quantity FROM lineitem GROUP BY l_partkey&quot;
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = HIVE
Constraints.Output0.Engine.location = slave-1
Constraints.Output0.type = SQL
Execution.Argument0 = tpchQuery17InnerHive.sql
Execution.Arguments.number = 1
Execution.LuaScript = InnerSQL_Hive.lua
Execution.Output0.name = PART_AGG
Execution.Output0.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2))
Optimization.Out0.size = (In0.size)*0.1
Optimization.cost = 15.0
Optimization.execTime = 50000.0
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>t0</input>
    </operators>
    <operators>
        <name>t1</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>stopped</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = HIVE
Constraints.Engine.location = slave-1
Constraints.type = SQL
Execution.name = PART_AGG
Execution.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2))
Optimization.size = 0.1
</description>
        <abstractName>d1</abstractName>
        <isTarget>false</isTarget>
        <input>InnerSQL_Hive_0</input>
    </operators>
    <operators>
        <name>Move_Hive_Spark_6</name>
        <cost>0.82</cost>
        <execTime>0.82</execTime>
        <status>stopped</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = Spark
Constraints.EngineSpecification.Distributed.Spark.masterLocation = master
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = HIVE
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = move
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = Spark
Constraints.Output0.Engine.location = master
Constraints.Output0.type = SQL
Execution.Argument0 = In0.name
Execution.Argument1 = In0.schema
Execution.Argument2 = spark://master:7077
Execution.Arguments.number = 3
Execution.LuaScript = Move_Hive_Spark.lua
Execution.Output0.name = In0.name
Execution.Output0.schema = In0.schema
Optimization.Out0.size = In0.size
Optimization.cost = 1.0
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>t1</input>
    </operators>
    <operators>
        <name>t2</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = PostgreSQL
Constraints.Engine.location = slave-1
Constraints.type = SQL
Execution.name = lineitem
Execution.schema = ( l_orderkey bigint, l_partkey bigint, l_suppkey bigint, l_linenumber int, l_quantity decimal, l_extendedprice decimal, l_discount decimal, l_tax decimal, l_returnflag char( 1),   l_linestatus char( 1), l_shipdate date, l_commitdate date, l_receiptdate date, l_shipinstruct char( 25), l_shipmode char( 10), l_comment varchar( 44))
Optimization.size = 1
</description>
        <abstractName>lineitem</abstractName>
        <isTarget>false</isTarget>
        <input>lineitem</input>
    </operators>
    <operators>
        <name>InnerSQL_Postgres_1</name>
        <cost>55.57</cost>
        <execTime>55.57</execTime>
        <status>warn</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = PostgreSQL
Constraints.EngineSpecification.Centralized.PostgreSQL.location = slave-1
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = PostgreSQL
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = SQL_query
Constraints.OpSpecification.SQL_query = &quot;SELECT l_partkey AS agg_partkey, 0.2 * avg(l_quantity) AS avg_quantity FROM lineitem GROUP BY l_partkey&quot;
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = PostgreSQL
Constraints.Output0.Engine.location = slave-1
Constraints.Output0.type = SQL
Execution.Argument0 = &quot;DROP TABLE IF EXISTS part_agg; CREATE TABLE part_agg AS SELECT l_partkey AS agg_partkey, 0.2 * AVG(l_quantity) AS avg_quantity FROM lineitem GROUP BY l_partkey&quot;
Execution.Argument1 = postgres
Execution.Arguments.number = 2
Execution.LuaScript = InnerSQL_Postgres.lua
Execution.Output0.name = part_agg
Execution.Output0.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2))
Optimization.Out0.size = (In0.size)*0.1
Optimization.cost = 2500.0
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>t2</input>
    </operators>
    <operators>
        <name>t3</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = PostgreSQL
Constraints.Engine.location = slave-1
Constraints.type = SQL
Execution.name = part_agg
Execution.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2))
Optimization.size = 0.1
</description>
        <abstractName>d1</abstractName>
        <isTarget>false</isTarget>
        <input>InnerSQL_Postgres_1</input>
    </operators>
    <operators>
        <name>Move_Postgres_Spark_7</name>
        <cost>26.77</cost>
        <execTime>26.77</execTime>
        <status>warn</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = Spark
Constraints.EngineSpecification.Distributed.Spark.masterLocation = master
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = PostgreSQL
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = move
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = Spark
Constraints.Output0.Engine.location = master
Constraints.Output0.type = SQL
Execution.Argument0 = postgres
Execution.Argument1 = In0.name
Execution.Argument2 = In0.schema
Execution.Argument3 = spark://master:7077
Execution.Arguments.number = 4
Execution.LuaScript = Move_Postgres_Spark.lua
Execution.Output0.name = In0.name
Execution.Output0.schema = In0.schema
Optimization.Out0.size = In0.size
Optimization.cost = 1.0
Optimization.execTime = In0.size/1.2
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>t3</input>
    </operators>
    <operators>
        <name>Move_Postgres_Spark_4</name>
        <cost>26.77</cost>
        <execTime>26.77</execTime>
        <status>stopped</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = Spark
Constraints.EngineSpecification.Distributed.Spark.masterLocation = master
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = PostgreSQL
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = move
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = Spark
Constraints.Output0.Engine.location = master
Constraints.Output0.type = SQL
Execution.Argument0 = postgres
Execution.Argument1 = In0.name
Execution.Argument2 = In0.schema
Execution.Argument3 = spark://master:7077
Execution.Arguments.number = 4
Execution.LuaScript = Move_Postgres_Spark.lua
Execution.Output0.name = In0.name
Execution.Output0.schema = In0.schema
Optimization.Out0.size = In0.size
Optimization.cost = 1.0
Optimization.execTime = In0.size/1.2
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>lineitem</input>
    </operators>
    <operators>
        <name>t4</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>stopped</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = Spark
Constraints.Engine.location = master
Constraints.type = SQL
Execution.name = lineitem
Execution.schema = ( l_orderkey bigint, l_partkey bigint, l_suppkey bigint, l_linenumber int, l_quantity decimal, l_extendedprice decimal, l_discount decimal, l_tax decimal, l_returnflag char( 1),   l_linestatus char( 1), l_shipdate date, l_commitdate date, l_receiptdate date, l_shipinstruct char( 25), l_shipmode char( 10), l_comment varchar( 44))
Optimization.size = 1.0
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>Move_Postgres_Spark_4</input>
    </operators>
    <operators>
        <name>InnerSQL_Spark_2</name>
        <cost>2500.00</cost>
        <execTime>2500.00</execTime>
        <status>stopped</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = Spark
Constraints.EngineSpecification.Distributed.Spark.masterLocation = master
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = Spark
Constraints.Input0.Engine.location = master
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = SQL_query
Constraints.OpSpecification.SQL_query = &quot;SELECT l_partkey AS agg_partkey, 0.2 * avg(l_quantity) AS avg_quantity FROM lineitem GROUP BY l_partkey&quot;
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = Spark
Constraints.Output0.Engine.location = master
Constraints.Output0.type = SQL
Execution.Argument0 = spark://master:7077
Execution.Argument1 = executeInnerSQL.py
Execution.Argument2 = master
Execution.Argument3 = /opt/hadoop-2.7.0
Execution.Argument4 = tpchQuery17InnerSpark.sql
Execution.Arguments.number = 5
Execution.LuaScript = InnerSQL_Spark.lua
Execution.Output0.name = part_aggParquet
Execution.Output0.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2), agg_extendedprice decimal( 10,2))
Optimization.Out0.size = (In0.size)*0.1
Optimization.cost = 25.0
Optimization.execTime = 2500.0
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>t4</input>
    </operators>
    <operators>
        <name>t5</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>stopped</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = Spark
Constraints.Engine.location = master
Constraints.type = SQL
Execution.name = part_aggParquet
Execution.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2), agg_extendedprice decimal( 10,2))
Optimization.size = 0.1
</description>
        <abstractName>d1</abstractName>
        <isTarget>false</isTarget>
        <input>InnerSQL_Spark_2</input>
    </operators>
    <operators>
        <name>t6</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = Spark
Constraints.Engine.location = master
Constraints.type = SQL
Execution.name = part_agg
Execution.schema = (agg_partkey bigint, avg_quantity decimal( 10, 2))
Optimization.size = 0.1
</description>
        <abstractName>t5</abstractName>
        <isTarget>false</isTarget>
        <input>Move_Hive_Spark_6</input>
        <input>Move_Postgres_Spark_7</input>
        <input>t5</input>
    </operators>
    <operators>
        <name>part</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = PostgreSQL
Constraints.Engine.location = slave-1
Constraints.type = SQL
Execution.name = part
Execution.schema = ( p_partkey int, p_name varchar( 55), p_mfgr char( 25), p_brand char( 10), p_type varchar( 25), p_size int, p_container char( 10), p_retailprice decimal( 10, 2), p_comment varchar( 23))
Optimization.size = 1
</description>
        <abstractName>part</abstractName>
        <isTarget>false</isTarget>
    </operators>
    <operators>
        <name>Move_Postgres_Spark_8</name>
        <cost>26.77</cost>
        <execTime>26.77</execTime>
        <status>warn</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = Spark
Constraints.EngineSpecification.Distributed.Spark.masterLocation = master
Constraints.Input.number = 1
Constraints.Input0.Engine.SQL = PostgreSQL
Constraints.Input0.Engine.location = slave-1
Constraints.Input0.type = SQL
Constraints.OpSpecification.Algorithm.name = move
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = Spark
Constraints.Output0.Engine.location = master
Constraints.Output0.type = SQL
Execution.Argument0 = postgres
Execution.Argument1 = In0.name
Execution.Argument2 = In0.schema
Execution.Argument3 = spark://master:7077
Execution.Arguments.number = 4
Execution.LuaScript = Move_Postgres_Spark.lua
Execution.Output0.name = In0.name
Execution.Output0.schema = In0.schema
Optimization.Out0.size = In0.size
Optimization.cost = 1.0
Optimization.execTime = In0.size/1.2
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>part</input>
    </operators>
    <operators>
        <name>t7</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = Spark
Constraints.Engine.location = master
Constraints.type = SQL
Execution.name = part
Execution.schema = ( p_partkey int, p_name varchar( 55), p_mfgr char( 25), p_brand char( 10), p_type varchar( 25), p_size int, p_container char( 10), p_retailprice decimal( 10, 2), p_comment varchar( 23))
Optimization.size = 1.0
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>Move_Postgres_Spark_8</input>
    </operators>
    <operators>
        <name>OutterSQL_Spark_5</name>
        <cost>55.57</cost>
        <execTime>55.57</execTime>
        <status>warn</status>
        <isOperator>true</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine = Spark
Constraints.EngineSpecification.Distributed.Spark.masterLocation = master
Constraints.Input.number = 2
Constraints.Input0.Engine.SQL = Spark
Constraints.Input0.Engine.location = master
Constraints.Input0.type = SQL
Constraints.Input1.Engine.SQL = Spark
Constraints.Input1.Engine.location = master
Constraints.Input1.type = SQL
Constraints.OpSpecification.Algorithm.name = SQL_query
Constraints.OpSpecification.SQL_query = &quot;select sum(l_extendedprice) / 7.0 as avg_yearly from lineitem, part, part_agg where p_partkey = l_partkey and agg_partkey = l_partkey and p_brand = 'Brand#33' and p_container = 'MED BAG' and l_quantity &lt; avg_quantity LIMIT 1;&quot;
Constraints.Output.number = 1
Constraints.Output0.Engine.SQL = Spark
Constraints.Output0.Engine.location = master
Constraints.Output0.type = SQL
Execution.Argument0 = spark://master:7077
Execution.Argument1 = executeOutterSQL.py
Execution.Argument2 = master
Execution.Argument3 = /opt/hadoop-2.7.0
Execution.Argument4 = tpchQuery17OutterSpark.sql
Execution.Arguments.number = 5
Execution.LuaScript = OutterSQL_Spark.lua
Execution.Output0.name = finalParquet
Execution.Output0.schema = ( avg_yearly decimal( 10, 2))
Optimization.Out0.size = (In0.size)*0.1
Optimization.cost = 25.0
Optimization.inputSpace.In0.size = Double,1,20,5
Optimization.model.Out0.size = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.cost = gr.ntua.ece.cslab.panic.core.models.UserFunction
Optimization.model.execTime = gr.ntua.ece.cslab.panic.core.models.AbstractWekaModel
Optimization.outputSpace.Out0.size = Double
Optimization.outputSpace.cost = Double
Optimization.outputSpace.execTime = Double
</description>
        <abstractName></abstractName>
        <isTarget>false</isTarget>
        <input>t6</input>
        <input>t7</input>
    </operators>
    <operators>
        <name>t8</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description>Constraints.Engine.SQL = Spark
Constraints.Engine.location = master
Constraints.type = SQL
Execution.name = finalParquet
Execution.schema = ( avg_yearly decimal( 10, 2))
Optimization.size = 0.010000000000000002
</description>
        <abstractName>d2</abstractName>
        <isTarget>false</isTarget>
        <input>OutterSQL_Spark_5</input>
    </operators>
    <operators>
        <name>d2</name>
        <cost>0.00</cost>
        <execTime>0.00</execTime>
        <status>warn</status>
        <isOperator>false</isOperator>
        <isAbstract>false</isAbstract>
        <description></description>
        <abstractName>d2</abstractName>
        <isTarget>true</isTarget>
        <input>t8</input>
    </operators>
    <name></name>
    <indexes/>
    <graph/>
    <isUpdated>false</isUpdated>
</workflow>
